{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b20a1-51b8-44db-843c-4b9caec51d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Style for plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a66521-3cc8-4e12-bc3f-58ca8d5861ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72826ddc-96bd-49c0-8054-d497d97d203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c6ff2-1843-4f57-86c2-cb735d84f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c793ec-55d5-4cc8-9e06-b83639e8c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e343425-f0ff-4947-880b-80465eae21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] = df['Class'].astype(int)  # ensure column is int\n",
    "\n",
    "sns.countplot(x='Class', hue='Class', data=df, palette={0: 'skyblue', 1: 'red'}, legend=False)\n",
    "plt.title(\"Class Distribution (0 = Normal, 1 = Fraud)\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "fraud_ratio = df['Class'].value_counts(normalize=True)[1] * 100\n",
    "print(f\"Fraudulent transactions: {fraud_ratio:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593134f-d4b3-4318-9151-9da4f61e6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfa036-675a-4ced-bf06-13f3876c70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8061932-7ff0-43b3-acb5-7f03268a7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)  # reduce to 10 principal components\n",
    "X_pca_reduced = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2c33b-5008-421b-8ed2-45e140279f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.Class.value_counts()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(counts, labels=counts.index, autopct='%1.1f%%', \n",
    "        startangle=140)\n",
    "\n",
    "plt.title('Distribution of a Target Variable')\n",
    "plt.axis('equal')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e395817-4ea4-47f3-adda-2a0574e826e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] = df['Class'].astype(int)\n",
    "\n",
    "sns.boxplot(x='Class', y='Amount', hue='Class', data=df,\n",
    "            palette={0: 'lightgreen', 1: 'orangered'}, legend=False)\n",
    "\n",
    "plt.title(\"Transaction Amount by Class\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Amount\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6f61d-f09d-4433-93b9-78fea5cdcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "top_corr = corr['Class'].abs().sort_values(ascending=False).head(10)\n",
    "\n",
    "print(\"Top 10 features most correlated with Class:\\n\", top_corr)\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr[top_corr.index].loc[top_corr.index], annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Top Correlated Features with Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794b4de-d359-4ce6-bf2c-2e37c370bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['Amount'], bins=5, color='purple', kde=True)\n",
    "plt.title(\"Distribution of Transaction Amounts\")\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424a486-961d-45df-81ab-f8e06a7745d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# 5 nearest neighbors since min_samples = 5\n",
    "neighbors = NearestNeighbors(n_neighbors=5)\n",
    "neighbors_fit = neighbors.fit(X_scaled)\n",
    "distances, indices = neighbors_fit.kneighbors(X_scaled)\n",
    "\n",
    "# Sort and plot the 5th nearest distances\n",
    "distances = np.sort(distances[:, 4])\n",
    "plt.plot(distances)\n",
    "plt.title(\"k-distance graph (use elbow point as eps)\")\n",
    "plt.xlabel(\"Points sorted by distance\")\n",
    "plt.ylabel(\"5th Nearest Neighbor Distance\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42247499-c2d6-4f1b-a584-94616f15c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_sample, _, = train_test_split(X_pca_reduced, train_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0a287-3eb1-4d97-821a-868fcc34c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "eps_values = [1.5, 1.8, 2.0, 2.2, 2.4]\n",
    "min_samples_values = [3, 5, 7]\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = db.fit_predict(X_sample)\n",
    "\n",
    "        score = silhouette_score(X_sample, labels) if len(set(labels)) > 1 else -1\n",
    "        noise = np.sum(labels == -1)\n",
    "        clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "        print(f\"eps={eps}, min_samples={min_samples} â†’ Clusters: {clusters}, Noise: {noise}, Silhouette: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22098b7-fa0a-4012-b9ef-feb22a16b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_final_sample, _,y_final_sample,_= train_test_split(X_pca_reduced, df['Class'], train_size=50000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb829e8-a786-4d66-90ab-ad3c2f0ca2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "db_final = DBSCAN(eps=2.2, min_samples=5)\n",
    "labels_final = db_final.fit_predict(X_final_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ac5fc-a48f-4436-ac33-0c6b6fb55123",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.DataFrame(X_final_sample)\n",
    "new_df[\"Clusters\"]=labels_final\n",
    "print(\"Unique clusters found by DBSCAN:\", np.unique(labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c30f57-df18-4ee1-bc38-f3bb73660095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many points per cluster\n",
    "cluster_counts = new_df.value_counts()\n",
    "print(\"Points per cluster:\\n\", cluster_counts)\n",
    "\n",
    "# How many are anomalies?\n",
    "n_anomalies = (new_df['Clusters'] == -1).sum()\n",
    "print(f\"Total anomalies (cluster = -1): {n_anomalies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aee5d2-d7cd-4583-8bd8-8f073d506ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to label anomalies\n",
    "new_df['Anomaly'] = new_df['Clusters'].apply(lambda x: 'Anomaly' if x == -1 else 'Normal')\n",
    "\n",
    "# View anomaly distribution\n",
    "sns.countplot(x='Anomaly', hue='Anomaly', data=new_df,palette={'Normal': 'blue', 'Anomaly': 'red'}, legend=False)\n",
    "plt.title(\"DBSCAN-Detected Anomalies\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb61519c-222f-47e1-9bc3-ad9c81514188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_vis = PCA(n_components=2)\n",
    "X_pca_2d = pca_vis.fit_transform(X_final_sample)  # Use PCA-10 version as input\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=labels_final, cmap='tab10', s=5)\n",
    "plt.title(\"DBSCAN Clustering (50K Sample, PCA-reduced)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar(label='Cluster ID')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eaf9a3-2e48-4871-8098-d0d291207941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(X_final_sample)\n",
    "\n",
    "# Add PCA results to the original DataFrame\n",
    "new_df['PCA1'] = pca_result[:, 0]\n",
    "new_df['PCA2'] = pca_result[:, 1]\n",
    "\n",
    "# Check explained variance\n",
    "print(f\"PCA Explained Variance Ratio: {pca.explained_variance_ratio_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f703b-3e14-4af7-884d-c2d0cb3ecf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cluster distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    x='PCA1',\n",
    "    y='PCA2',\n",
    "    hue='Clusters',\n",
    "    data=new_df,\n",
    "    palette='tab10',\n",
    "    alpha=0.6,\n",
    "    edgecolor=None,\n",
    "    legend='full'\n",
    ")\n",
    "plt.title(\"DBSCAN Clusters Visualized in PCA Space\", fontsize=14, weight='bold')\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend(title='Cluster ID', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9ee11-5970-4cb9-ae66-bc31c5424f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight anomalies in red and normal in green\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    x='PCA1',\n",
    "    y='PCA2',\n",
    "    hue='Anomaly',\n",
    "    data=new_df,\n",
    "    palette={'Normal': 'green', 'Anomaly': 'red'},\n",
    "    alpha=0.6,\n",
    "    edgecolor=None\n",
    ")\n",
    "plt.title(\"Anomaly vs Normal Transactions in PCA Space\", fontsize=14, weight='bold')\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend(title='Transaction Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e542bc4-8208-4a71-ab8d-7ff2e17686c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "sample_indices = np.random.choice(len(X_final_sample), size=5000, replace=False)\n",
    "X_sample = X_final_sample[sample_indices]\n",
    "labels_sample = labels_final[sample_indices]\n",
    "\n",
    "n_clusters = len(set(labels_sample)) - (1 if -1 in labels_sample else 0)\n",
    "silhouette = silhouette_score(X_sample, labels_sample) if n_clusters > 1 else -1\n",
    "noise_count = np.sum(labels_sample == -1)\n",
    "\n",
    "# Final Output\n",
    "print(f\"Sampled 5000 points from 50K PCA-reduced set:\")\n",
    "print(f\"Clusters found: {n_clusters}\")\n",
    "print(f\"Noise points in sample: {noise_count}\")\n",
    "print(f\"Silhouette Score: {silhouette:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b81f93-a452-4063-86f1-830179411f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce 10D PCA sample to 2D for visualization\n",
    "X_pca_sample_2D = PCA(n_components=2).fit_transform(X_sample)\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_pca_sample_2D[:, 0], X_pca_sample_2D[:, 1], c=labels_sample, cmap='tab10', s=8, alpha=0.8)\n",
    "plt.title(\"DBSCAN Clusters on Sample (PCA-2D Projection)\", fontsize=14, weight='bold')\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.grid(True)\n",
    "plt.colorbar(label='Cluster ID')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"dbscan_sample_clusters.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73c919-d8c9-4f30-b1d3-376f031bca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Clusters: {n_clusters}, Noise points: {noise_count}, Silhouette: {silhouette:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506dd6d4-2217-4905-b9bb-183956545a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted: if cluster = -1, we assume it might be fraud\n",
    "new_df['Predicted_Fraud'] = new_df['Clusters'].apply(lambda x: 1 if x == -1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d844d4-7f6c-4b97-ac04-dde6c36b4d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(X_final_sample == -1, 1, 0)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d66e8e-12f3-4402-9ee3-61066900c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Flatten y_true to 1D if it's a DataFrame or 2D array\n",
    "if hasattr(y_true, 'values'):\n",
    "    y_true = y_true.values  # Convert pandas Series/DataFrame to NumPy array\n",
    "\n",
    "y_true = np.ravel(y_true)  # Flattens it to 1D\n",
    "y_pred = np.ravel(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b31ae-9e72-4898-8fb2-bfe453500980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure y_true and y_pred are 1D arrays\n",
    "y_true = np.ravel(y_final_sample)\n",
    "y_pred = np.where(labels_final == -1, 1, 0)\n",
    "\n",
    "# Shapes check (optional)\n",
    "print(\"Shapes:\", y_true.shape, y_pred.shape)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Fraud'])\n",
    "\n",
    "# Plot with aesthetic customizations\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "disp.plot(ax=ax, cmap='YlOrRd', colorbar=False)  # You can try 'Blues', 'Purples', etc.\n",
    "\n",
    "# Enhance title and axis labels\n",
    "plt.title(\"ðŸ’¡ Confusion Matrix: DBSCAN vs True Labels\", fontsize=14, weight='bold', color='darkblue')\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "plt.grid(False)\n",
    "\n",
    "# Make tick labels bold and larger\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "    label.set_fontweight('bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4756cf4-98dd-48b4-813a-3015c5dc5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=[\"Normal\", \"Fraud\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117055ca-93e5-4584-80d9-5d28b48e721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(db_final,\"dbscan_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaaa0ac-4f74-479c-87a7-559591e18259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54422bac-441c-4d2b-a484-d3c9655430d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9889f-4187-4106-a918-28fbc1d1ce33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (NLTK)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
